{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "\n",
    "sc =SparkContext.getOrCreate()\n",
    "#загружаем файлы\n",
    "dfTrain = spark.read.format('csv').options(header='true', \n",
    "                                            inferSchema='true').load('/home/zorro/VM/BigData/Spark/titanic/train.csv')\n",
    "dfTest = spark.read.format('csv').options(header='true', \n",
    "                                            inferSchema='true').load('/home/zorro/VM/BigData/Spark/titanic/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+-----------------+------------------+--------+\n",
      "|summary|          Survived|            Pclass|   Sex|              Age|              Fare|Embarked|\n",
      "+-------+------------------+------------------+------+-----------------+------------------+--------+\n",
      "|  count|               712|               712|   712|              712|               712|     712|\n",
      "|   mean|0.4044943820224719| 2.240168539325843|  null|29.64209269662921| 34.56725140449432|    null|\n",
      "| stddev|0.4911389472541192|0.8368543166903446|  null|14.49293290032352|52.938648174710906|    null|\n",
      "|    min|                 0|                 1|female|             0.42|               0.0|       C|\n",
      "|    max|                 1|                 3|  male|             80.0|          512.3292|       S|\n",
      "+-------+------------------+------------------+------+-----------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Выбираем влияющие на выживаемость показатели\n",
    "train_df = dfTrain.select(['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked'])\n",
    "#удалим поля null\n",
    "train_df = train_df.na.drop()\n",
    "train_df.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем текстовые столбцы в числовые для распознавания машинныи мозгом\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer, StringIndexer, OneHotEncoder\n",
    "sex_indexer = StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
    "sex_encoder = OneHotEncoder(inputCol='SexIndex', outputCol='SexVec')\n",
    "\n",
    "embarked_indexer = StringIndexer(inputCol='Embarked', outputCol='EmbarkedIndex')\n",
    "embarked_encoder = OneHotEncoder(inputCol='EmbarkedIndex', outputCol='EmbarkedVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = VectorAssembler(inputCols=['Pclass', 'SexVec', 'Age', 'Fare', 'EmbarkedVec'], outputCol='AllFeatures')\n",
    "#используем логистическую регрессию\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "logistic_reg_model = LogisticRegression(featuresCol='AllFeatures', labelCol='Survived')\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[sex_indexer, embarked_indexer, sex_encoder, embarked_encoder, \n",
    "                            res, logistic_reg_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем модель для обучения\n",
    "model_fill = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+------------------+------------------+--------+\n",
      "|summary|       PassengerId|            Pclass|   Sex|               Age|              Fare|Embarked|\n",
      "+-------+------------------+------------------+------+------------------+------------------+--------+\n",
      "|  count|               418|               418|   418|               418|               418|     418|\n",
      "|   mean|            1100.5|2.2655502392344498|  null|30.272590361445815|  35.6271884892086|    null|\n",
      "| stddev|120.81045760473994|0.8418375519640503|  null|12.634534168325061|55.840500479541056|    null|\n",
      "|    min|               892|                 1|female|              0.17|               0.0|       C|\n",
      "|    max|              1309|                 3|  male|              76.0|          512.3292|       S|\n",
      "+-------+------------------+------------------+------+------------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Подготовка данных для тестового набора и результат будет из двух полей Survived по PassengerId\n",
    "test_df = dfTest.select(['PassengerId', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked'])\n",
    "#расчет средних значений\n",
    "age_mean = test_df.agg({'Age': 'mean'}).first()[0]\n",
    "fare_mean = test_df.agg({'Fare': 'mean'}).first()[0]\n",
    "#проставим вместо null средние значения для того, чтобы все столбцы были равны по строкам\n",
    "test_df = test_df.fillna(age_mean, subset=['Age'])\n",
    "test_df = test_df.fillna(fare_mean, subset=['Fare'])\n",
    "test_df.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Передаем тестовые данные в модель для анализап модели\n",
    "results = model_fill.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|PassengerId|prediction|\n",
      "+-----------+----------+\n",
      "|        892|       0.0|\n",
      "|        893|       0.0|\n",
      "|        894|       0.0|\n",
      "|        895|       0.0|\n",
      "|        896|       1.0|\n",
      "|        897|       0.0|\n",
      "|        898|       0.0|\n",
      "|        899|       0.0|\n",
      "|        900|       1.0|\n",
      "|        901|       0.0|\n",
      "|        902|       0.0|\n",
      "|        903|       0.0|\n",
      "|        904|       1.0|\n",
      "|        905|       0.0|\n",
      "|        906|       1.0|\n",
      "|        907|       1.0|\n",
      "|        908|       0.0|\n",
      "|        909|       0.0|\n",
      "|        910|       1.0|\n",
      "|        911|       1.0|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Результаты по ID выживет или нет (1/0)\n",
    "#out_results = results.select('PassengerId', 'prediction', 'probability')\n",
    "out_results = results.select('PassengerId', 'prediction')\n",
    "out_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение результата в CSV файл\n",
    "import pandas as pd\n",
    "out_results.toPandas().to_csv(r'/home/zorro/VM/BigData/Spark/titanic/titanic_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
