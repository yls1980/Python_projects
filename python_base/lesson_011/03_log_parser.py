# -*- coding: utf-8 -*-
import os


# На основе своего кода из lesson_009/02_log_parser.py напишите итератор (или генератор)
# котрый читает исходный файл events.txt и выдает число событий NOK за каждую минуту
# <время> <число повторений>
#
# пример использования:
#
# grouped_events = <создание итератора/генератора>  # Итератор или генератор? выбирайте что вам более понятно
# for group_time, event_count in grouped_events:
#     print(f'[{group_time}] {event_count}')
#
# на консоли должно появится что-то вроде
#
# [2018-05-17 01:57] 1234

def grouped_events():
    # mins = collections.defaultdict(int)
    log_file = 'events.txt'
    read_pos = 17
    # mins.clear()
    #  Лучше немного изменить логику проверки и если файла нет, писать сообщение и делать
    #  пустой return. После этого можно поместить оставшийся код с уменьшенным отступом.
    if not os.path.exists(log_file):
        print(f'Файл {log_file} не существует')
        return
    else:
        rfile = open(log_file, 'r')
        #  Начальное значение calc должно зависеть от того заканчивается ли
        #  первая строка на NOK или нет. Сейчас, если в файле с данными будут
        #  первые две строки за один временной интервал, где первая заканчивается
        #  на OK, а вторая на NOK, то для временного интервала вместо одного
        #  события будет записано 2.
        calc = 0
        smin = ''
        # С помощью функции next можно считать первую строку из
        #  файла и сохранить её в smin.
        # first_row = next(rfile)
        # if first_row[-4:].strip() == 'NOK':
        #    smin = first_row[1:read_pos]
        #    calc = 1
        buf = ''
        for line in rfile:
            if line[-4:].strip() == 'NOK':
                if smin == '':
                    smin = line[1:read_pos]
                if smin == line[1:read_pos]:
                    calc += 1
                else:
                    yield smin, calc
                    buf = smin
                    calc = 1
                smin = line[1:read_pos]
                # mins[smin] += 1
        else:
            if buf != smin:
                yield smin, calc
        rfile.close()
        # for minute in mins:
        #    yield minute, mins[minute]


#  В процессе работы выводятся лишние строки:
#  [2018-05-14 19:38] 1
#  [2018-05-14 19:38] 2
#  [2018-05-14 19:38] 3
#  [2018-05-14 19:38] 4
#  ...
#  [2018-05-14 20:04] 1
#  [2018-05-14 20:04] 2
#  [2018-05-14 20:04] 3
#  Должно быть по одной записи на временной интервал
#  [2018-05-14 19:38] 4
#  [2018-05-14 19:39] 1
#  [2018-05-14 19:40] 1
#  ...
#  [2018-05-14 20:03] 1
#  [2018-05-14 20:04] 3
#  [2018-05-14 20:05] 2


#  События в файле отсортированы по возрастанию даты и времени.
#  Поэтому нет необходимости предварительно обрабатывать данные, и только потом возвращать.
#  Такой подход не оптимален из-за необходимости хранить все данные.
#  Нужно переделать код таким образом, чтобы возвращать (yield) результат сразу после его получения.
#  Т. е. хранить нужно только счётчик событий и строку с текущим периодом времени.
#  При обработке строки нужно проверять, что период совпадает, и тогда нужно только увеличить
#  счётчик. Если значение не совпадает, то нужно возвращать период и накопленное количество событий.
#  И заменяете старый период на новый. После завершения цикла по строкам файлов нужно сделать
#  заключительным yield, возвращая последний накопленный результат.

# for group_time, event_count in aaa:
#    print(f'[{group_time}] {event_count}')
for group_time, event_count in grouped_events():
    print(f'[{group_time}] {event_count}')

# Не забывайте про оформление кода.

# Зачёт!
